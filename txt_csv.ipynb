{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's what I'm going to need:\n",
    "\n",
    "import time, glob\n",
    "import os\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import concurrent.futures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path = 'C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/econlit_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilepath = 'C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/'\n",
    "outfilename = outfilepath + 'all_files' + \".txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 15641: expected 11 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "filenames = os.listdir('C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah1')\n",
    "\n",
    "\n",
    "path_txt = 'C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah1'\n",
    "col_list = [ 'AU', 'AF', 'SO', 'DT', 'DE', 'PT', 'IS', 'UD', 'AN','\\n']\n",
    "\n",
    "\n",
    "with open(outfilename, 'wt') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(path_txt+'/'+fname, 'rt') as readfile:\n",
    "            infile = readfile.readlines()\n",
    "            for line in infile:\n",
    "                if line[:2] in col_list: outfile.write(line[4:])\n",
    "                elif line[:2] == 'TI': outfile.write('\\n'+line[4:])\n",
    "            outfile.write(\"\\n\\n\")\n",
    "            \n",
    "            \n",
    "with open(outfilename, 'r') as f:\n",
    "    data = f.read().replace('\\n','@').replace('@@','\\n')\n",
    "    \n",
    "data = data[1:]\n",
    "\n",
    "    \n",
    "set1 = pd.read_csv(pd.compat.StringIO(data), header=None, sep = '@', low_memory=True, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "\n",
    "filenames = os.listdir('C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah2')\n",
    "\n",
    "\n",
    "path_txt = 'C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah2'\n",
    "col_list = [ 'AU', 'AF', 'SO', 'DT', 'DE', 'PT', 'IS', 'UD', 'AN','\\n']\n",
    "\n",
    "\n",
    "with open(outfilename, 'wt') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(path_txt+'/'+fname, 'rt') as readfile:\n",
    "            infile = readfile.readlines()\n",
    "            for line in infile:\n",
    "                if line[:2] in col_list: outfile.write(line[4:])\n",
    "                elif line[:2] == 'TI': outfile.write('\\n'+line[4:])\n",
    "            outfile.write(\"\\n\\n\")\n",
    "            \n",
    "            \n",
    "with open(outfilename, 'r') as f:\n",
    "    data = f.read().replace('\\n','@').replace('@@','\\n')\n",
    "    \n",
    "data = data[1:]\n",
    "\n",
    "    \n",
    "set2 = pd.read_csv(pd.compat.StringIO(data), header=None, sep = '@', low_memory=True, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 14663: expected 10 fields, saw 11\\nSkipping line 24014: expected 10 fields, saw 11\\nSkipping line 26959: expected 10 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "filenames = os.listdir('C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah3')\n",
    "\n",
    "\n",
    "path_txt = 'C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah3'\n",
    "col_list = [ 'AU', 'AF', 'SO', 'DT', 'DE', 'PT', 'IS', 'UD', 'AN','\\n']\n",
    "\n",
    "\n",
    "with open(outfilename, 'wt') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(path_txt+'/'+fname, 'rt') as readfile:\n",
    "            infile = readfile.readlines()\n",
    "            for line in infile:\n",
    "                if line[:2] in col_list: outfile.write(line[4:])\n",
    "                elif line[:2] == 'TI': outfile.write('\\n'+line[4:])\n",
    "            outfile.write(\"\\n\\n\")\n",
    "            \n",
    "            \n",
    "with open(outfilename, 'r') as f:\n",
    "    data = f.read().replace('\\n','@').replace('@@','\\n')\n",
    "    \n",
    "data = data[1:]\n",
    "\n",
    "    \n",
    "set3 = pd.read_csv(pd.compat.StringIO(data), header=None, sep = '@', low_memory=True, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 12774: expected 10 fields, saw 11\\nSkipping line 49019: expected 10 fields, saw 11\\n'\n",
      "b'Skipping line 67173: expected 10 fields, saw 11\\nSkipping line 69253: expected 10 fields, saw 11\\n'\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "filenames = os.listdir('C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah4')\n",
    "\n",
    "\n",
    "path_txt = 'C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah4'\n",
    "col_list = [ 'AU', 'AF', 'SO', 'DT', 'DE', 'PT', 'IS', 'UD', 'AN','\\n']\n",
    "\n",
    "\n",
    "with open(outfilename, 'wt') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(path_txt+'/'+fname, 'rt') as readfile:\n",
    "            infile = readfile.readlines()\n",
    "            for line in infile:\n",
    "                if line[:2] in col_list: outfile.write(line[4:])\n",
    "                elif line[:2] == 'TI': outfile.write('\\n'+line[4:])\n",
    "            outfile.write(\"\\n\\n\")\n",
    "            \n",
    "            \n",
    "with open(outfilename, 'r') as f:\n",
    "    data = f.read().replace('\\n','@').replace('@@','\\n')\n",
    "    \n",
    "data = data[1:]\n",
    "\n",
    "    \n",
    "set4 = pd.read_csv(pd.compat.StringIO(data), header=None, sep = '@', low_memory=True, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers = pd.concat([set1, set2, set3, set4], ignore_index=True)\n",
    "\n",
    "#d_df = dd.from_pandas(all_papers, chunksize=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>What Could Happen in a Monetary Union? The Per...</td>\n",
       "      <td>Oros, Cornel</td>\n",
       "      <td>CRIEF, U Poitiers and U Orleans</td>\n",
       "      <td>Journal of Economic Integration, December 2012...</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>Asymmetric and Private Information; Mechanism ...</td>\n",
       "      <td>1225651X</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>20171201.0</td>\n",
       "      <td>1675313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Price Dynamics Homogeneous across Eurozone ...</td>\n",
       "      <td>Guerreiro, David; Joets, Marc; Mignon, Valerie</td>\n",
       "      <td>U Paris, Ouest Nanterre La Defense and CNRS; U...</td>\n",
       "      <td>Journal of Economic Integration, December 2012...</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>Price Level; Inflation; Deflation          (E3...</td>\n",
       "      <td>1225651X</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>20171201</td>\n",
       "      <td>1675312.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic Integration in the Indian Subcontinen...</td>\n",
       "      <td>Jayaraman, T. K.; Choong, Chee-Keong</td>\n",
       "      <td>U South Pacific; U Tunku Abdul Rahman</td>\n",
       "      <td>Journal of Economic Integration, December 2012...</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>Economic Integration          (F15); Economic ...</td>\n",
       "      <td>1225651X</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>20171201</td>\n",
       "      <td>1675311.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Testing the Asset-Seeking Hypothesis: Through ...</td>\n",
       "      <td>Yong, He; Hong, Zhou</td>\n",
       "      <td>U Auvergne; Fudan U</td>\n",
       "      <td>Journal of Economic Integration, December 2012...</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>Firm Behavior: Empirical Analysis          (D2...</td>\n",
       "      <td>1225651X</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>20171201</td>\n",
       "      <td>1675310.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The European Fiscal Compact: A Counterfactual ...</td>\n",
       "      <td>Creel, Jerome; Hubert, Paul; Saraceno, Francesco</td>\n",
       "      <td>Observatoire Francais des Conjonctures Economi...</td>\n",
       "      <td>Journal of Economic Integration, December 2012...</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>Macroeconomics: Production          (E23); Pri...</td>\n",
       "      <td>1225651X</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>20171201</td>\n",
       "      <td>1675309.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   \\\n",
       "0                                                NaN   \n",
       "1  Is Price Dynamics Homogeneous across Eurozone ...   \n",
       "2  Economic Integration in the Indian Subcontinen...   \n",
       "3  Testing the Asset-Seeking Hypothesis: Through ...   \n",
       "4  The European Fiscal Compact: A Counterfactual ...   \n",
       "\n",
       "                                                  1   \\\n",
       "0  What Could Happen in a Monetary Union? The Per...   \n",
       "1     Guerreiro, David; Joets, Marc; Mignon, Valerie   \n",
       "2               Jayaraman, T. K.; Choong, Chee-Keong   \n",
       "3                               Yong, He; Hong, Zhou   \n",
       "4   Creel, Jerome; Hubert, Paul; Saraceno, Francesco   \n",
       "\n",
       "                                                  2   \\\n",
       "0                                       Oros, Cornel   \n",
       "1  U Paris, Ouest Nanterre La Defense and CNRS; U...   \n",
       "2              U South Pacific; U Tunku Abdul Rahman   \n",
       "3                                U Auvergne; Fudan U   \n",
       "4  Observatoire Francais des Conjonctures Economi...   \n",
       "\n",
       "                                                  3   \\\n",
       "0                    CRIEF, U Poitiers and U Orleans   \n",
       "1  Journal of Economic Integration, December 2012...   \n",
       "2  Journal of Economic Integration, December 2012...   \n",
       "3  Journal of Economic Integration, December 2012...   \n",
       "4  Journal of Economic Integration, December 2012...   \n",
       "\n",
       "                                                  4   \\\n",
       "0  Journal of Economic Integration, December 2012...   \n",
       "1                                      December 2012   \n",
       "2                                      December 2012   \n",
       "3                                      December 2012   \n",
       "4                                      December 2012   \n",
       "\n",
       "                                                  5   \\\n",
       "0                                      December 2012   \n",
       "1  Price Level; Inflation; Deflation          (E3...   \n",
       "2  Economic Integration          (F15); Economic ...   \n",
       "3  Firm Behavior: Empirical Analysis          (D2...   \n",
       "4  Macroeconomics: Production          (E23); Pri...   \n",
       "\n",
       "                                                  6                7   \\\n",
       "0  Asymmetric and Private Information; Mechanism ...         1225651X   \n",
       "1                                           1225651X  Journal Article   \n",
       "2                                           1225651X  Journal Article   \n",
       "3                                           1225651X  Journal Article   \n",
       "4                                           1225651X  Journal Article   \n",
       "\n",
       "                8           9          10  \n",
       "0  Journal Article  20171201.0  1675313.0  \n",
       "1         20171201   1675312.0        NaN  \n",
       "2         20171201   1675311.0        NaN  \n",
       "3         20171201   1675310.0        NaN  \n",
       "4         20171201   1675309.0        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers.to_csv('C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/10_14_all.csv', chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "\n",
    "filenames = os.listdir('C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah3')\n",
    "\n",
    "\n",
    "path_txt = 'C:/Users/240-370-8956/Dropbox/Research/JEL_codes/Data/econlit_txt/blah3'\n",
    "col_list = [ 'AU', 'AF', 'SO', 'DT', 'DE', 'PT', 'IS', 'UD', 'AN','\\n']\n",
    "\n",
    "\n",
    "with open(outfilename, 'wt') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(path_txt+'/'+fname, 'rt') as readfile:\n",
    "            infile = readfile.readlines()\n",
    "            for line in infile:\n",
    "                if line[:2] in col_list: outfile.write(line[4:])\n",
    "                elif line[:2] == 'TI': outfile.write('\\n'+line[4:])\n",
    "            outfile.write(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outfilepath + 'all_1606590872'+'.txt', 'r') as f:\n",
    "    data = f.read().replace('\\n','@').replace('@@','\\n')\n",
    "    \n",
    "data = data[1:]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Un modello di governance per i processi di trasformazione urbana culture led. (A Model of Governance for Urban Culture Led Transformation Processes. With English summary.)@Crociata, Alessandro@G d'Annunzio U Chieti-Pescara@Risparmio, April-June 2010, v. 58, iss. 2, pp. 67-97@April-June 2010@Positive Analysis of Policy Formulation and Implementation          (D78); Regional Economic Activity: Growth, Development, Environmental Issues, and Changes          (R11); Regional Development Planning and Policy          (R58); Economic Sociology; Economic Anthropology; Language; Social and Economic Stratification          (Z13); @00355615@Journal Article@20170601@1642841\\nIl mezzogiorno nella storia d'italia. (The Mezzogiorno in the Italian History. With English summary.)@Sabattini, Gianfranco@U Cagliari@Risparmio, April-June 2010, v. 58, iss. 2, pp. 35-66@April-June 2010@Macroeconomics: Production          (E23); Regional and Urban History: Europe: Pre-1913          (N93); Regional and Urban His\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 14663: expected 10 fields, saw 11\\nSkipping line 24014: expected 10 fields, saw 11\\nSkipping line 26959: expected 10 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "set3 = pd.read_csv(pd.compat.StringIO(data), header=None, sep = '@', low_memory=True, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
